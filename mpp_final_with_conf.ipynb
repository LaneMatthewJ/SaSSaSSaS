{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mpp_classifiers as mpp\n",
    "import load_ship_data as lsd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data using our own data loader\n",
    "\n",
    "NOTE: Confusion Matrix is incorrect. \n",
    "\n",
    "I corrected it in reported results, but left it this way in code\n",
    "\n",
    "so that results would line up with report.\n",
    "\n",
    "Rerunning with correct matrix would cause our random split to alter the results slightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Data Length:  2800   Label Length:  2800\n",
      "TestingSet Set Data Length:  600  Label Length:  600\n",
      "Validation Set Data Length:  600  Label Length:  600\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_path=\"data/shipsnet.json\"\n",
    "train,test,valid=lsd.load_data_train_test_split(data_path)\n",
    "def conf(pred,y):\n",
    "    T0=sum([1 if x==y and y==0 else 0 for (x,y) in zip(pred,y)])\n",
    "    T1=sum([1 if x==y and y==1 else 0 for (x,y) in zip(pred,y)])\n",
    "    F0=sum([1 if x!=y and y==0 else 0 for (x,y) in zip(pred,y)])\n",
    "    F1=sum([1 if x!=y and y==1 else 0 for (x,y) in zip(pred,y)])\n",
    "    return np.array([[T0,T1],[F0,F1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup data splits and priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75035714 0.24964286]\n",
      "(2800, 19200)\n",
      "(600, 19200)\n",
      "(600, 19200)\n"
     ]
    }
   ],
   "source": [
    "ship_prob=np.sum(train[1])*1.0/train[1].shape[0]\n",
    "p=np.array([1-ship_prob,ship_prob])\n",
    "print(p)\n",
    "Xtrain=train[0]\n",
    "ytrain=train[1]\n",
    "Xtest=test[0]\n",
    "ytest=test[1]\n",
    "Xvalid=valid[0]\n",
    "yvalid=valid[1]\n",
    "Xtrain=Xtrain.reshape(Xtrain.shape[0],Xtrain.shape[1]*Xtrain.shape[2]*Xtrain.shape[3])\n",
    "Xtest=Xtest.reshape(Xtest.shape[0],Xtest.shape[1]*Xtest.shape[2]*Xtest.shape[3])\n",
    "Xvalid=Xvalid.reshape(Xvalid.shape[0],Xvalid.shape[1]*Xvalid.shape[2]*Xvalid.shape[3])\n",
    "print(Xtrain.shape)\n",
    "print(Xtest.shape)\n",
    "print(Xvalid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 1. No PCA, even priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.6633333333333333;\n",
      "Classwise accuracy = [0.65759637 0.67924528];\n",
      "The learning process takes 14.288885354995728 seconds.\n",
      "[[290 108]\n",
      " [151  51]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "p55=np.array([.5,.5])\n",
    "t0 = time.time()           # start time\n",
    "y_model = mpp.mpp(Xtrain, ytrain, Xtest, 1, p55)\n",
    "t1 = time.time()           # ending time\n",
    "acc_classwise, acc_overall = mpp.accuracy_score(ytest, y_model)\n",
    "print(f'Overall accuracy = {acc_overall};')\n",
    "print(f'Classwise accuracy = {acc_classwise};')\n",
    "print(f'The learning process takes {t1 - t0} seconds.')\n",
    "ar=conf(y_model,ytest)\n",
    "print(ar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 2. No PCA, prior assumes ships are rare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.735;\n",
      "Classwise accuracy = [1. 0.];\n",
      "The learning process takes 14.406003713607788 seconds.\n",
      "[[441   0]\n",
      " [  0 159]]\n"
     ]
    }
   ],
   "source": [
    "p91=np.array([.9,.1])\n",
    "t0 = time.time()           # start time\n",
    "y_model = mpp.mpp(Xtrain, ytrain, Xtest, 1, p91)\n",
    "t1 = time.time()           # ending time\n",
    "acc_classwise, acc_overall = mpp.accuracy_score(ytest, y_model)\n",
    "print(f'Overall accuracy = {acc_overall};')\n",
    "print(f'Classwise accuracy = {acc_classwise};')\n",
    "print(f'The learning process takes {t1 - t0} seconds.')\n",
    "ar=conf(y_model,ytest)\n",
    "print(ar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 1. No PCA, priors from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.7366666666666667;\n",
      "Classwise accuracy = [1.         0.00628931];\n",
      "The learning process takes 14.272328853607178 seconds.\n",
      "[[441   1]\n",
      " [  0 158]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t0 = time.time()           # start time\n",
    "y_model = mpp.mpp(Xtrain, ytrain, Xtest, 1, p)\n",
    "t1 = time.time()           # ending time\n",
    "acc_classwise, acc_overall = mpp.accuracy_score(ytest, y_model)\n",
    "print(f'Overall accuracy = {acc_overall};')\n",
    "print(f'Classwise accuracy = {acc_classwise};')\n",
    "print(f'The learning process takes {t1 - t0} seconds.')\n",
    "ar=conf(y_model,ytest)\n",
    "print(ar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA = 800 dimensions kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9906665778462846\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=800)\n",
    "pca.fit(Xtrain)\n",
    "pca_Xtrain=pca.transform(Xtrain)\n",
    "pca_Xtest=pca.transform(Xtest)\n",
    "explained=np.sum(pca.explained_variance_ratio_)\n",
    "print(explained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 1. PCA=800, training priors used from now on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.7366666666666667;\n",
      "Classwise accuracy = [1.         0.00628931];\n",
      "The learning process takes 0.08228778839111328 seconds.\n",
      "[[441   1]\n",
      " [  0 158]]\n"
     ]
    }
   ],
   "source": [
    "p=np.array([1-ship_prob,ship_prob])\n",
    "t0 = time.time()           # start time\n",
    "y_model = mpp.mpp(pca_Xtrain, ytrain, pca_Xtest, 1, p)\n",
    "t1 = time.time()           # ending time\n",
    "acc_classwise, acc_overall = mpp.accuracy_score(ytest, y_model)\n",
    "print(f'Overall accuracy = {acc_overall};')\n",
    "print(f'Classwise accuracy = {acc_classwise};')\n",
    "print(f'The learning process takes {t1 - t0} seconds.')\n",
    "ar=conf(y_model,ytest)\n",
    "print(ar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 2. PCA=800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.9016666666666666;\n",
      "Classwise accuracy = [0.92290249 0.8427673 ];\n",
      "The learning process takes 24.81798505783081 seconds.\n",
      "[[407 134]\n",
      " [ 34  25]]\n"
     ]
    }
   ],
   "source": [
    "p=np.array([1-ship_prob,ship_prob])\n",
    "t0 = time.time()           # start time\n",
    "y_model = mpp.mpp(pca_Xtrain, ytrain, pca_Xtest, 2, p)\n",
    "t1 = time.time()           # ending time\n",
    "acc_classwise, acc_overall = mpp.accuracy_score(ytest, y_model)\n",
    "print(f'Overall accuracy = {acc_overall};')\n",
    "print(f'Classwise accuracy = {acc_classwise};')\n",
    "print(f'The learning process takes {t1 - t0} seconds.')\n",
    "ar=conf(y_model,ytest)\n",
    "print(ar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 3. PCA=800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.5083333333333333;\n",
      "Classwise accuracy = [0.52380952 0.46540881];\n",
      "The learning process takes 31.980409622192383 seconds.\n",
      "[[231  74]\n",
      " [210  85]]\n"
     ]
    }
   ],
   "source": [
    "p=np.array([1-ship_prob,ship_prob])\n",
    "t0 = time.time()           # start time\n",
    "y_model = mpp.mpp(pca_Xtrain, ytrain, pca_Xtest, 3, p)\n",
    "t1 = time.time()           # ending time\n",
    "acc_classwise, acc_overall = mpp.accuracy_score(ytest, y_model)\n",
    "print(f'Overall accuracy = {acc_overall};')\n",
    "print(f'Classwise accuracy = {acc_classwise};')\n",
    "print(f'The learning process takes {t1 - t0} seconds.')\n",
    "ar=conf(y_model,ytest)\n",
    "print(ar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA =200 dimensions kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9425671638421523\n"
     ]
    }
   ],
   "source": [
    "pca2 = PCA(n_components=200)\n",
    "pca2.fit(Xtrain)\n",
    "pca2_Xtrain=pca2.transform(Xtrain)\n",
    "pca2_Xtest=pca2.transform(Xtest)\n",
    "explained=np.sum(pca2.explained_variance_ratio_)\n",
    "print(explained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 1. PCA=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.74;\n",
      "Classwise accuracy = [1.         0.01886792];\n",
      "The learning process takes 0.024442195892333984 seconds.\n",
      "[[441   3]\n",
      " [  0 156]]\n"
     ]
    }
   ],
   "source": [
    "p=np.array([1-ship_prob,ship_prob])\n",
    "t0 = time.time()           # start time\n",
    "y_model = mpp.mpp(pca2_Xtrain, ytrain, pca2_Xtest, 1, p)\n",
    "t1 = time.time()           # ending time\n",
    "acc_classwise, acc_overall = mpp.accuracy_score(ytest, y_model)\n",
    "print(f'Overall accuracy = {acc_overall};')\n",
    "print(f'Classwise accuracy = {acc_classwise};')\n",
    "print(f'The learning process takes {t1 - t0} seconds.')\n",
    "ar=conf(y_model,ytest)\n",
    "print(ar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 2. PCA=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.9233333333333333;\n",
      "Classwise accuracy = [0.96145125 0.81761006];\n",
      "The learning process takes 0.569476842880249 seconds.\n",
      "[[424 130]\n",
      " [ 17  29]]\n"
     ]
    }
   ],
   "source": [
    "p=np.array([1-ship_prob,ship_prob])\n",
    "t0 = time.time()           # start time\n",
    "y_model = mpp.mpp(pca2_Xtrain, ytrain, pca2_Xtest, 2, p)\n",
    "t1 = time.time()           # ending time\n",
    "acc_classwise, acc_overall = mpp.accuracy_score(ytest, y_model)\n",
    "print(f'Overall accuracy = {acc_overall};')\n",
    "print(f'Classwise accuracy = {acc_classwise};')\n",
    "print(f'The learning process takes {t1 - t0} seconds.')\n",
    "ar=conf(y_model,ytest)\n",
    "print(ar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 3. PCA=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.8283333333333334;\n",
      "Classwise accuracy = [0.81632653 0.86163522];\n",
      "The learning process takes 0.9020977020263672 seconds.\n",
      "[[360 137]\n",
      " [ 81  22]]\n"
     ]
    }
   ],
   "source": [
    "p=np.array([1-ship_prob,ship_prob])\n",
    "t0 = time.time()           # start time\n",
    "y_model = mpp.mpp(pca2_Xtrain, ytrain, pca2_Xtest, 3, p)\n",
    "t1 = time.time()           # ending time\n",
    "acc_classwise, acc_overall = mpp.accuracy_score(ytest, y_model)\n",
    "print(f'Overall accuracy = {acc_overall};')\n",
    "print(f'Classwise accuracy = {acc_classwise};')\n",
    "print(f'The learning process takes {t1 - t0} seconds.')\n",
    "ar=conf(y_model,ytest)\n",
    "print(ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join training and validation since upcoming cross-validation will do this split for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9391647331330492\n"
     ]
    }
   ],
   "source": [
    "pca2 = PCA(n_components=200)\n",
    "Xtrain=np.concatenate((Xtrain,Xvalid))\n",
    "ytrain=np.concatenate((ytrain,yvalid))\n",
    "pca2.fit(Xtrain)\n",
    "pca2_Xtrain=pca2.transform(Xtrain)\n",
    "pca2_Xtest=pca2.transform(Xtest)\n",
    "explained=np.sum(pca2.explained_variance_ratio_)\n",
    "print(explained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup for Kfold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=np.array([1-ship_prob,ship_prob])\n",
    "X=pca2_Xtrain\n",
    "y=ytrain\n",
    "k=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from each fold =  [0.7176470588235294, 0.7470588235294118, 0.7294117647058823, 0.7529411764705882, 0.7558823529411764, 0.7676470588235295, 0.7558823529411764, 0.788235294117647, 0.75, 0.7735294117647059]\n",
      "Average Accuracy = 0.7538235294117647\n",
      "0.7735294117647059\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kf=KFold(n_splits=k,random_state=None)\n",
    "acc_scores=[]\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train,X_test=X[train_index,:],X[test_index,:]\n",
    "    y_train,y_test=y[train_index],y[test_index]\n",
    "    y_model = mpp.mpp(X_train, y_train, X_test, 1, p)\n",
    "    acc_classwise, acc_overall = mpp.accuracy_score(y_test, y_model)\n",
    "    acc_scores.append(acc_overall)\n",
    "avg_acc=sum(acc_scores)*1.0/k\n",
    "print('Accuracy from each fold =  {}'.format(acc_scores))\n",
    "print('Average Accuracy = {}'.format(avg_acc))\n",
    "y_model = mpp.mpp(X_train, y_train, X_test, 1, p)\n",
    "acc_classwise, acc_overall = mpp.accuracy_score(y_test, y_model)\n",
    "print(acc_overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from each fold =  [0.9176470588235294, 0.9088235294117647, 0.9176470588235294, 0.9411764705882353, 0.9235294117647059, 0.9264705882352942, 0.9264705882352942, 0.9294117647058824, 0.9264705882352942, 0.9058823529411765]\n",
      "Average Accuracy = 0.9223529411764707\n",
      "0.9058823529411765\n"
     ]
    }
   ],
   "source": [
    "kf=KFold(n_splits=k,random_state=None)\n",
    "acc_scores=[]\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train,X_test=X[train_index,:],X[test_index,:]\n",
    "    y_train,y_test=y[train_index],y[test_index]\n",
    "    y_model = mpp.mpp(X_train, y_train, X_test, 2, p)\n",
    "    acc_classwise, acc_overall = mpp.accuracy_score(y_test, y_model)\n",
    "    acc_scores.append(acc_overall)\n",
    "avg_acc=sum(acc_scores)*1.0/k\n",
    "print('Accuracy from each fold =  {}'.format(acc_scores))\n",
    "print('Average Accuracy = {}'.format(avg_acc))\n",
    "y_model = mpp.mpp(X_train, y_train, X_test, 2, p)\n",
    "acc_classwise, acc_overall = mpp.accuracy_score(y_test, y_model)\n",
    "print(acc_overall)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from each fold =  [0.7941176470588235, 0.7441176470588236, 0.8058823529411765, 0.7617647058823529, 0.8352941176470589, 0.788235294117647, 0.7852941176470588, 0.788235294117647, 0.8058823529411765, 0.8235294117647058]\n",
      "Average Accuracy = 0.793235294117647\n",
      "0.8235294117647058\n"
     ]
    }
   ],
   "source": [
    "kf=KFold(n_splits=k,random_state=None)\n",
    "acc_scores=[]\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train,X_test=X[train_index,:],X[test_index,:]\n",
    "    y_train,y_test=y[train_index],y[test_index]\n",
    "    y_model = mpp.mpp(X_train, y_train, X_test, 3, p)\n",
    "    acc_classwise, acc_overall = mpp.accuracy_score(y_test, y_model)\n",
    "    acc_scores.append(acc_overall)\n",
    "avg_acc=sum(acc_scores)*1.0/k\n",
    "print('Accuracy from each fold =  {}'.format(acc_scores))\n",
    "print('Average Accuracy = {}'.format(avg_acc))\n",
    "y_model = mpp.mpp(X_train, y_train, X_test, 3, p)\n",
    "acc_classwise, acc_overall = mpp.accuracy_score(y_test, y_model)\n",
    "print(acc_overall)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
