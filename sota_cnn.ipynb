{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://www.kaggle.com/tomras/cnn-classifier-using-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam, SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import pydot\n",
    "import load_ship_data as lsd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This notebook assumes keras-gpu is installed instead of the regular keras\n",
    "\n",
    "Note: You'll need to downgrade to python 3.7 to install keras-gpu\n",
    "\n",
    "Check for GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10198986979239463533\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6610781471\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10699102043536263858\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Data Length:  2800   Label Length:  2800\n",
      "TestingSet Set Data Length:  600  Label Length:  600\n",
      "Validation Set Data Length:  600  Label Length:  600\n",
      "[0.7525 0.2475]\n",
      "(2800, 3, 80, 80)\n",
      "(600, 3, 80, 80)\n",
      "(600, 3, 80, 80)\n",
      "(3400, 3, 80, 80)\n",
      "(3400, 2)\n",
      "(3400,) (3400, 3, 80, 80)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(522)\n",
    "data_path=\"data/shipsnet.json\"\n",
    "train,test,valid=lsd.load_data_train_test_split(data_path)\n",
    "ship_prob=np.sum(train[1])*1.0/train[1].shape[0]\n",
    "p=np.array([1-ship_prob,ship_prob])\n",
    "print(p)\n",
    "Xtrain=train[0]\n",
    "ytrain=train[1]\n",
    "Xtest=test[0]\n",
    "ytest=test[1]\n",
    "Xvalid=valid[0]\n",
    "yvalid=valid[1]\n",
    "#Xtrain=Xtrain.reshape(Xtrain.shape[0],Xtrain.shape[1]*Xtrain.shape[2]*Xtrain.shape[3])\n",
    "#Xtest=Xtest.reshape(Xtest.shape[0],Xtest.shape[1]*Xtest.shape[2]*Xtest.shape[3])\n",
    "#Xvalid=Xvalid.reshape(Xvalid.shape[0],Xvalid.shape[1]*Xvalid.shape[2]*Xvalid.shape[3])\n",
    "print(Xtrain.shape)\n",
    "print(Xtest.shape)\n",
    "print(Xvalid.shape)\n",
    "Xtrain=np.concatenate((Xtrain,Xvalid))\n",
    "Xtrain=Xtrain/255\n",
    "Xtest=Xtest/255\n",
    "ytrain=np.concatenate((ytrain,yvalid))\n",
    "y_train_mono=ytrain\n",
    "y_test_mono=ytest\n",
    "ytrain=to_categorical(ytrain,num_classes=2)\n",
    "ytest=to_categorical(ytest,num_classes=2)\n",
    "print(Xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(y_train_mono.shape,Xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3400, 80, 80, 3)\n",
      "(600, 80, 80, 3)\n"
     ]
    }
   ],
   "source": [
    "Xtrain=Xtrain.reshape(-1,80,80,3)\n",
    "Xtest=Xtest.reshape(-1,80,80,3)\n",
    "print(Xtrain.shape)\n",
    "print(Xtest.shape)\n",
    "X_train=Xtrain\n",
    "X_test=Xtest\n",
    "y_train=ytrain\n",
    "y_test=ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=(80, 80, 3), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01, momentum=0.9, nesterov=True), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2890 samples, validate on 510 samples\n",
      "Epoch 1/40\n",
      "2890/2890 [==============================] - 2s 766us/step - loss: 0.4012 - accuracy: 0.8204 - val_loss: 0.2706 - val_accuracy: 0.9000\n",
      "Epoch 2/40\n",
      "2890/2890 [==============================] - 2s 690us/step - loss: 0.1785 - accuracy: 0.9273 - val_loss: 0.1256 - val_accuracy: 0.9392accuracy: 0. - ETA: 0s - loss: 0.2\n",
      "Epoch 3/40\n",
      "2890/2890 [==============================] - 2s 690us/step - loss: 0.1018 - accuracy: 0.9668 - val_loss: 0.0511 - val_accuracy: 0.9804\n",
      "Epoch 4/40\n",
      "2890/2890 [==============================] - 2s 690us/step - loss: 0.0597 - accuracy: 0.9806 - val_loss: 0.0745 - val_accuracy: 0.9706 - loss: 0.0629 -  - ETA: 0s - loss: 0.0738 - accuracy: 0. - ETA: 0s - loss: 0.0707 - accuracy - ETA: 0s - loss: 0.065\n",
      "Epoch 5/40\n",
      "2890/2890 [==============================] - 2s 695us/step - loss: 0.0544 - accuracy: 0.9830 - val_loss: 0.0430 - val_accuracy: 0.9902curacy:  - ETA: 0s - loss: 0.0509 - accuracy: 0. - ETA: 0s - loss: 0.0493 - accuracy: 0. - ETA: 0s - loss: 0.0549 - accuracy: 0.98\n",
      "Epoch 6/40\n",
      "2890/2890 [==============================] - 2s 695us/step - loss: 0.0334 - accuracy: 0.9879 - val_loss: 0.0539 - val_accuracy: 0.9804- accuracy: 0.98 - ETA: 0s - loss: 0.0274 - accuracy: 0.98 - ETA: 0s - loss: 0.0271 - accuracy: 0. - ETA: 0s - loss: 0.0289 - ac\n",
      "Epoch 7/40\n",
      "2890/2890 [==============================] - 2s 691us/step - loss: 0.0312 - accuracy: 0.9879 - val_loss: 0.0341 - val_accuracy: 0.9882 - loss: 0.047 - ETA: 0s - loss: 0\n",
      "Epoch 8/40\n",
      "2890/2890 [==============================] - 2s 697us/step - loss: 0.0223 - accuracy: 0.9941 - val_loss: 0.0359 - val_accuracy: 0.9902 - loss: 0.0220 - accuracy: 0.99\n",
      "Epoch 9/40\n",
      "2890/2890 [==============================] - 2s 696us/step - loss: 0.0127 - accuracy: 0.9969 - val_loss: 0.0374 - val_accuracy: 0.9882.0116 \n",
      "Epoch 10/40\n",
      "2890/2890 [==============================] - 2s 696us/step - loss: 0.0122 - accuracy: 0.9962 - val_loss: 0.0295 - val_accuracy: 0.9902\n",
      "Epoch 11/40\n",
      "2890/2890 [==============================] - 2s 695us/step - loss: 0.0139 - accuracy: 0.9945 - val_loss: 0.0550 - val_accuracy: 0.9843148 - accuracy: 0.99 - ETA: 0s - loss: 0.0141 - ac - ETA: 0s - loss: 0.0130 - accuracy:  - ETA: 0s - loss: 0.0139 - accu\n",
      "Epoch 12/40\n",
      "2890/2890 [==============================] - 2s 690us/step - loss: 0.0134 - accuracy: 0.9965 - val_loss: 0.0661 - val_accuracy: 0.9902 - ETA: 0s - loss: 0.0099 - ac\n",
      "Epoch 13/40\n",
      "2890/2890 [==============================] - 2s 702us/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 0.0645 - val_accuracy: 0.9863\n",
      "Epoch 14/40\n",
      "2890/2890 [==============================] - 2s 705us/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0387 - val_accuracy: 0.9941 - loss: 0.007 - ETA: 0s - loss: 0.0074 - accuracy: 0.99 - ETA: 0s - loss: 0.0074 - accura - ETA: 0s - loss: 0.0080 - accu - ETA: 0s - loss: 0.0073 - accuracy: 0.99\n",
      "Epoch 15/40\n",
      "2890/2890 [==============================] - 2s 690us/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0564 - val_accuracy: 0.9902\n",
      "Epoch 16/40\n",
      "2890/2890 [==============================] - 2s 698us/step - loss: 0.0157 - accuracy: 0.9938 - val_loss: 0.0765 - val_accuracy: 0.9784\n",
      "Epoch 17/40\n",
      "2890/2890 [==============================] - 2s 698us/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 0.0387 - val_accuracy: 0.98630s - loss: 0.0090 - accura - ETA: 0s - loss: 0.0093 - accuracy: \n",
      "Epoch 18/40\n",
      "2890/2890 [==============================] - 2s 697us/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0549 - val_accuracy: 0.9882\n",
      "Epoch 19/40\n",
      "2890/2890 [==============================] - 2s 703us/step - loss: 0.0080 - accuracy: 0.9958 - val_loss: 0.0409 - val_accuracy: 0.9902\n",
      "Epoch 20/40\n",
      "2890/2890 [==============================] - 2s 693us/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.0542 - val_accuracy: 0.9882\n",
      "Epoch 21/40\n",
      "2890/2890 [==============================] - 2s 697us/step - loss: 0.0042 - accuracy: 0.9979 - val_loss: 0.0400 - val_accuracy: 0.9941s: 0.0 - ETA: 0s - loss: 0.0041 - accuracy: 0.\n",
      "Epoch 22/40\n",
      "2890/2890 [==============================] - 2s 698us/step - loss: 0.0075 - accuracy: 0.9969 - val_loss: 0.0927 - val_accuracy: 0.9863 - loss: 0.0052 - accuracy: 0. - ETA: 1s - loss: 0.0073 - accuracy:  - ETA: 0s - loss: 0.0063 - accuracy: 0.99 - ETA: 0s - los\n",
      "Epoch 23/40\n",
      "2890/2890 [==============================] - 2s 696us/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0371 - val_accuracy: 0.9902\n",
      "Epoch 24/40\n",
      "2890/2890 [==============================] - 2s 699us/step - loss: 6.6466e-04 - accuracy: 1.0000 - val_loss: 0.0556 - val_accuracy: 0.98821s - loss: 8.1906e-04 - accuracy:  - ETA: 0s - loss: 7\n",
      "Epoch 25/40\n",
      "2890/2890 [==============================] - 2s 693us/step - loss: 4.2485e-04 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 0.9902\n",
      "Epoch 26/40\n",
      "2890/2890 [==============================] - 2s 708us/step - loss: 2.2001e-04 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9902 - loss: 2.7042e-04 - accuracy - ETA: 0s - loss:\n",
      "Epoch 27/40\n",
      "2890/2890 [==============================] - 2s 701us/step - loss: 1.4015e-04 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9922\n",
      "Epoch 28/40\n",
      "2890/2890 [==============================] - 2s 709us/step - loss: 2.3249e-04 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9902s: 2.7606e-04 - accuracy: 1.00 - ETA: 0s - loss: 2.751\n",
      "Epoch 29/40\n",
      "2890/2890 [==============================] - 2s 716us/step - loss: 9.9754e-05 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.99221s - loss: 1.1552e-04 - accuracy - ETA: 1s - loss: 1.4261e-04 - accuracy: 1.00 - ETA: 1s - loss: 1.3418e-04 - accura - ETA: 0s - loss: 1.2454e-04 - accu - ETA: 0s - loss: 1.0796e-04 - ac\n",
      "Epoch 30/40\n",
      "2890/2890 [==============================] - 2s 710us/step - loss: 1.5551e-04 - accuracy: 1.0000 - val_loss: 0.0615 - val_accuracy: 0.9902\n",
      "Epoch 31/40\n",
      "2890/2890 [==============================] - 2s 718us/step - loss: 1.0921e-04 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9902\n",
      "Epoch 32/40\n",
      "2890/2890 [==============================] - ETA: 0s - loss: 6.7913e-05 - accuracy: 1.0000 ETA: 0s - loss: 9.0663e-05 - accura - ETA: 0s - loss: 7.8415e-05 -  - 2s 719us/step - loss: 7.4297e-05 - accuracy: 1.0000 - val_loss: 0.0566 - val_accuracy: 0.9902\n",
      "Epoch 33/40\n",
      "2890/2890 [==============================] - 2s 722us/step - loss: 1.6392e-04 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9922oss: 1.5613e-04 - accuracy: 1.00 - ETA: 0s - loss: 1.4781e-04  - ETA: 0s - loss: 1.6282e-04 - accu\n",
      "Epoch 34/40\n",
      "2890/2890 [==============================] - 2s 722us/step - loss: 6.6303e-05 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9922\n",
      "Epoch 35/40\n",
      "2890/2890 [==============================] - 2s 718us/step - loss: 6.5796e-05 - accuracy: 1.0000 - val_loss: 0.0560 - val_accuracy: 0.9922\n",
      "Epoch 36/40\n",
      "2890/2890 [==============================] - 2s 717us/step - loss: 9.4692e-05 - accuracy: 1.0000 - val_loss: 0.0539 - val_accuracy: 0.9922\n",
      "Epoch 37/40\n",
      "2890/2890 [==============================] - 2s 710us/step - loss: 6.9668e-05 - accuracy: 1.0000 - val_loss: 0.0602 - val_accuracy: 0.9922.4851e-05 - accuracy: 1. - ETA: 0s - loss: 8.0492e-05 - accura\n",
      "Epoch 38/40\n",
      "2890/2890 [==============================] - 2s 713us/step - loss: 2.4437e-05 - accuracy: 1.0000 - val_loss: 0.0604 - val_accuracy: 0.9922.7941e-05 - accuracy: 1.00 - ETA: 0s - loss: 2.0935e-05 - accuracy - ETA: 0s - loss: 1.915\n",
      "Epoch 39/40\n",
      "2890/2890 [==============================] - 2s 718us/step - loss: 5.4412e-05 - accuracy: 1.0000 - val_loss: 0.0622 - val_accuracy: 0.9922\n",
      "Epoch 40/40\n",
      "2890/2890 [==============================] - 2s 719us/step - loss: 4.0864e-05 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9922s: 4.1601e-05 - accuracy: 1.00 - ETA: 0s - loss: 4.3587e-05 - accuracy: 1. - ETA: 0s - loss: 4.1\n",
      "600/600 [==============================] - 0s 297us/step\n",
      "Test loss: 0.030714893206249295\n",
      "Test accuracy: 0.9900000095367432\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=32, epochs=40, validation_split=0.15)\n",
    "score = model.evaluate(X_test, y_test) \n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 80, 80, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 78, 78, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 39, 39, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 39, 39, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 39, 39, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 37, 37, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 20736)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               10617344  \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 10,683,938\n",
      "Trainable params: 10,683,938\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y, y_model):\n",
    "    # calculate classification overall accuracy and classwise accuracy\n",
    "    \n",
    "    assert len(y) == len(y_model)\n",
    "    classn = len(np.unique(y))       # number of different classes\n",
    "    correct_all = y == y_model       # all correct classifications\n",
    "    acc_overall = np.sum(correct_all) / len(y)\n",
    "    acc_i = np.zeros(classn)\n",
    "    for i in range(classn):   \n",
    "        GT_i = y == i                # samples actually belong to class i\n",
    "        acc_i[i] = (np.sum(GT_i & correct_all) / np.sum(GT_i))\n",
    "        \n",
    "    return acc_i, acc_overall\n",
    "def conf(pred,y):\n",
    "    T0=sum([1 if x==y and y==0 else 0 for (x,y) in zip(pred,y)])\n",
    "    T1=sum([1 if x==y and y==1 else 0 for (x,y) in zip(pred,y)])\n",
    "    F0=sum([1 if x!=y and y==0 else 0 for (x,y) in zip(pred,y)])\n",
    "    F1=sum([1 if x!=y and y==1 else 0 for (x,y) in zip(pred,y)])\n",
    "    return np.array([[T0,F0],[F1,T1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3400, 80, 80, 3)\n",
      "(3400, 2)\n",
      "(3400,)\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "X=X_train\n",
    "y=y_train\n",
    "k=5\n",
    "kf=StratifiedKFold(n_splits=k,random_state=None)\n",
    "acc_scores=[]\n",
    "conf_mat=[]\n",
    "times=[]\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(y_train_mono.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although normally we could validate a Keras model using cross_val_score from scikit, in order to validate using the same Stratified KFold as our classifiers, we perform the cross validation manually below. cross_val_score can be fed a StratifiedKFold option, but this option is not compatible with the one-hot encoding used by the Kaggle CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "2720/2720 [==============================] - 2s 705us/step - loss: 0.4022 - accuracy: 0.82321s - ETA: 0s - loss: 0.4349 - accura\n",
      "Epoch 2/40\n",
      "2720/2720 [==============================] - 2s 624us/step - loss: 0.2163 - accuracy: 0.91140s - loss: 0.2162 - accuracy: \n",
      "Epoch 3/40\n",
      "2720/2720 [==============================] - 2s 628us/step - loss: 0.1123 - accuracy: 0.95741s - ETA: 0s - loss: 0.1141 - accuracy: \n",
      "Epoch 4/40\n",
      "2720/2720 [==============================] - 2s 626us/step - loss: 0.0707 - accuracy: 0.97791s - loss: 0.0532 - ac - ETA: 0s -\n",
      "Epoch 5/40\n",
      "2720/2720 [==============================] - 2s 633us/step - loss: 0.0451 - accuracy: 0.98460s - loss: 0.0538 - accu - ETA: 0s - loss: 0.045\n",
      "Epoch 6/40\n",
      "2720/2720 [==============================] - 2s 630us/step - loss: 0.0362 - accuracy: 0.9890\n",
      "Epoch 7/40\n",
      "2720/2720 [==============================] - 2s 627us/step - loss: 0.0289 - accuracy: 0.98971s - loss: 0.0375 - accuracy: 0.98 - ETA: 1s - loss: 0.0358 - ac - ETA: 0s - loss: 0.031\n",
      "Epoch 8/40\n",
      "2720/2720 [==============================] - 2s 626us/step - loss: 0.0249 - accuracy: 0.99191s - loss: 0.0127 - accuracy -\n",
      "Epoch 9/40\n",
      "2720/2720 [==============================] - 2s 635us/step - loss: 0.0203 - accuracy: 0.99450s - loss: 0.0222 - accuracy\n",
      "Epoch 10/40\n",
      "2720/2720 [==============================] - 2s 630us/step - loss: 0.0140 - accuracy: 0.99560s - loss: 0.008 - ETA: 0s - loss: 0.0110 - accuracy\n",
      "Epoch 11/40\n",
      "2720/2720 [==============================] - 2s 631us/step - loss: 0.0135 - accuracy: 0.99601s - loss: 0.0201 - ac - ETA: 1s\n",
      "Epoch 12/40\n",
      "2720/2720 [==============================] - 2s 637us/step - loss: 0.0123 - accuracy: 0.99521s - loss: 0.0132 - accura - ETA: 0s - loss: 0.0144 - accuracy: 0. - ETA: 0s - loss: 0.0142 - accuracy: 0.99 - ETA: 0s - loss: 0.0144 - accuracy: 0.99 - ETA: 0s - loss: 0.0141 - accuracy:  - ETA: 0s - loss: 0.0137 - accura\n",
      "Epoch 13/40\n",
      "2720/2720 [==============================] - 2s 632us/step - loss: 0.0121 - accuracy: 0.99600s -\n",
      "Epoch 14/40\n",
      "2720/2720 [==============================] - 2s 629us/step - loss: 0.0084 - accuracy: 0.99601s - loss: 0.0138 - accuracy: 0.99 -\n",
      "Epoch 15/40\n",
      "2720/2720 [==============================] - 2s 628us/step - loss: 0.0064 - accuracy: 0.99850s - loss: 0.0062 - accuracy: 0.99\n",
      "Epoch 16/40\n",
      "2720/2720 [==============================] - 2s 632us/step - loss: 0.0052 - accuracy: 0.99820s - loss: 0.0\n",
      "Epoch 17/40\n",
      "2720/2720 [==============================] - 2s 631us/step - loss: 0.0085 - accuracy: 0.99600s - loss: - ETA: 0s - loss: 0.0089 - accuracy: 0.\n",
      "Epoch 18/40\n",
      "2720/2720 [==============================] - 2s 633us/step - loss: 0.0032 - accuracy: 0.9996\n",
      "Epoch 19/40\n",
      "2720/2720 [==============================] - 2s 633us/step - loss: 0.0021 - accuracy: 0.9993TA: 1s -\n",
      "Epoch 20/40\n",
      "2720/2720 [==============================] - 2s 630us/step - loss: 0.0201 - accuracy: 0.9949\n",
      "Epoch 21/40\n",
      "2720/2720 [==============================] - 2s 632us/step - loss: 0.0027 - accuracy: 0.9996\n",
      "Epoch 22/40\n",
      "2720/2720 [==============================] - 2s 630us/step - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 23/40\n",
      "2720/2720 [==============================] - 2s 640us/step - loss: 8.5547e-04 - accuracy: 1.0000\n",
      "Epoch 24/40\n",
      "2720/2720 [==============================] - 2s 635us/step - loss: 3.8052e-04 - accuracy: 1.00000s - loss: 3.4803e-04  - ETA: 0s - loss: 3.8412e-04 - accuracy: \n",
      "Epoch 25/40\n",
      "2720/2720 [==============================] - 2s 652us/step - loss: 0.0011 - accuracy: 0.99960s - loss: 0.0\n",
      "Epoch 26/40\n",
      "2720/2720 [==============================] - 2s 653us/step - loss: 3.3774e-04 - accuracy: 1.0000\n",
      "Epoch 27/40\n",
      "2720/2720 [==============================] - 2s 656us/step - loss: 4.7423e-04 - accuracy: 1.00000s - loss: 5.4034e-04 - accuracy:  - ETA: 0s - loss: 4.9504e-04 - accuracy: 1.\n",
      "Epoch 28/40\n",
      "2720/2720 [==============================] - 2s 650us/step - loss: 3.7007e-04 - accuracy: 1.00000s - loss: 1.9\n",
      "Epoch 29/40\n",
      "2720/2720 [==============================] - 2s 646us/step - loss: 0.0056 - accuracy: 0.9989\n",
      "Epoch 30/40\n",
      "2720/2720 [==============================] - 2s 651us/step - loss: 0.0055 - accuracy: 0.9985\n",
      "Epoch 31/40\n",
      "2720/2720 [==============================] - 2s 653us/step - loss: 9.9533e-04 - accuracy: 0.99961s - - ETA: 0s - loss: 0.0012 - accu\n",
      "Epoch 32/40\n",
      "2720/2720 [==============================] - 2s 649us/step - loss: 4.4195e-04 - accuracy: 1.0000\n",
      "Epoch 33/40\n",
      "2720/2720 [==============================] - 2s 651us/step - loss: 0.0117 - accuracy: 0.99740s - loss: 0.0085 - \n",
      "Epoch 34/40\n",
      "2720/2720 [==============================] - 2s 651us/step - loss: 0.0064 - accuracy: 0.9978\n",
      "Epoch 35/40\n",
      "2720/2720 [==============================] - 2s 655us/step - loss: 0.0039 - accuracy: 0.99930s - loss:\n",
      "Epoch 36/40\n",
      "2720/2720 [==============================] - 2s 657us/step - loss: 8.7336e-04 - accuracy: 1.0000\n",
      "Epoch 37/40\n",
      "2720/2720 [==============================] - 2s 656us/step - loss: 5.1920e-04 - accuracy: 1.0000\n",
      "Epoch 38/40\n",
      "2720/2720 [==============================] - 2s 654us/step - loss: 1.7663e-04 - accuracy: 1.0000\n",
      "Epoch 39/40\n",
      "2720/2720 [==============================] - 2s 648us/step - loss: 4.4470e-04 - accuracy: 1.0000\n",
      "Epoch 40/40\n",
      "2720/2720 [==============================] - 2s 640us/step - loss: 2.8118e-04 - accuracy: 1.0000 loss: 0.0010 - accuracy: 1. - E\n",
      "Epoch 1/40\n",
      "2720/2720 [==============================] - 2s 709us/step - loss: 0.3457 - accuracy: 0.84780s - loss: 0.3836 - \n",
      "Epoch 2/40\n",
      "2720/2720 [==============================] - 2s 655us/step - loss: 0.1715 - accuracy: 0.92900s - loss: 0.1909 - \n",
      "Epoch 3/40\n",
      "2720/2720 [==============================] - 2s 655us/step - loss: 0.0841 - accuracy: 0.9684\n",
      "Epoch 4/40\n",
      "2720/2720 [==============================] - 2s 660us/step - loss: 0.0611 - accuracy: 0.97651s - loss: 0.0685 - accuracy: 0.97 -\n",
      "Epoch 5/40\n",
      "2720/2720 [==============================] - 2s 663us/step - loss: 0.0405 - accuracy: 0.98570s - loss: 0.0403 - accuracy: 0. - ETA: 0s - loss: 0.0393 - ac\n",
      "Epoch 6/40\n",
      "2720/2720 [==============================] - 2s 645us/step - loss: 0.0414 - accuracy: 0.98641s - loss: 0.0377 - accuracy: 0. - ETA\n",
      "Epoch 7/40\n",
      "2720/2720 [==============================] - 2s 645us/step - loss: 0.0295 - accuracy: 0.99040s - loss: 0.0335 - accuracy - ETA: 0s - loss: 0.0311 - accuracy - ETA: 0s - loss: 0.0285 - accuracy: 0.99\n",
      "Epoch 8/40\n",
      "2720/2720 [==============================] - 2s 650us/step - loss: 0.0284 - accuracy: 0.9901\n",
      "Epoch 9/40\n",
      "2720/2720 [==============================] - 2s 668us/step - loss: 0.0152 - accuracy: 0.9949TA: 0s - loss: 0.0137 - accura\n",
      "Epoch 10/40\n",
      "2720/2720 [==============================] - 2s 653us/step - loss: 0.0152 - accuracy: 0.99520s - loss: - ETA: 0s - loss: 0.0161 - accuracy: 0.\n",
      "Epoch 11/40\n",
      "2720/2720 [==============================] - 2s 656us/step - loss: 0.0202 - accuracy: 0.9952\n",
      "Epoch 12/40\n",
      "2720/2720 [==============================] - 2s 657us/step - loss: 0.0174 - accuracy: 0.99371s - loss: 0.0047 -  - ETA: 0s - loss:\n",
      "Epoch 13/40\n",
      "2720/2720 [==============================] - 2s 652us/step - loss: 0.0099 - accuracy: 0.99631s - loss: 0.0118 - ac - ETA: 0s - loss: 0.0102 - accuracy:  - ETA: 0s - loss: 0.0106 \n",
      "Epoch 14/40\n",
      "2720/2720 [==============================] - 2s 671us/step - loss: 0.0115 - accuracy: 0.9963\n",
      "Epoch 15/40\n",
      "2720/2720 [==============================] - 2s 660us/step - loss: 0.0116 - accuracy: 0.9960\n",
      "Epoch 16/40\n",
      "2720/2720 [==============================] - 2s 655us/step - loss: 0.0133 - accuracy: 0.99491s - los - ETA: 0s - loss: 0.0086 - accuracy:  - ETA: 0s - loss: 0.0089 - accuracy: \n",
      "Epoch 17/40\n",
      "2720/2720 [==============================] - 2s 663us/step - loss: 0.0042 - accuracy: 0.99891s - loss: 0.0068 - accuracy: 0. - ETA: 1s - loss: 0.0073  - ETA: 0s - loss: 0.004\n",
      "Epoch 18/40\n",
      "2720/2720 [==============================] - 2s 662us/step - loss: 0.0032 - accuracy: 0.9989\n",
      "Epoch 19/40\n",
      "2720/2720 [==============================] - 2s 678us/step - loss: 0.0045 - accuracy: 0.99820s - loss: 0.0051 - accuracy:  - ETA: 0s - loss:\n",
      "Epoch 20/40\n",
      "2720/2720 [==============================] - 2s 655us/step - loss: 0.0067 - accuracy: 0.9974\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2720/2720 [==============================] - 2s 645us/step - loss: 7.0935e-04 - accuracy: 1.00000s - loss: 9.019\n",
      "Epoch 22/40\n",
      "2720/2720 [==============================] - 2s 650us/step - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 23/40\n",
      "2720/2720 [==============================] - 2s 648us/step - loss: 0.0013 - accuracy: 1.0000 - ETA: 0s - loss: 0.0012 - accuracy: 1.00\n",
      "Epoch 24/40\n",
      "2720/2720 [==============================] - 2s 646us/step - loss: 4.2774e-04 - accuracy: 1.00000s - loss: 4.7708e-04 - accu\n",
      "Epoch 25/40\n",
      "2720/2720 [==============================] - 2s 654us/step - loss: 4.5824e-04 - accuracy: 1.00000s - loss: 5.0222e-04 - ac\n",
      "Epoch 26/40\n",
      "2720/2720 [==============================] - 2s 653us/step - loss: 4.9424e-04 - accuracy: 1.00000s - loss: 7.0591e-04 - ac - ETA: 0s - loss: 5.8713e-04 - accura\n",
      "Epoch 27/40\n",
      "2720/2720 [==============================] - 2s 653us/step - loss: 2.9334e-04 - accuracy: 1.00000s - loss: 3.1118e-04 - accuracy: 1.\n",
      "Epoch 28/40\n",
      "2720/2720 [==============================] - 2s 660us/step - loss: 1.6193e-04 - accuracy: 1.0000\n",
      "Epoch 29/40\n",
      "2720/2720 [==============================] - 2s 668us/step - loss: 1.4932e-04 - accuracy: 1.0000\n",
      "Epoch 30/40\n",
      "2720/2720 [==============================] - ETA: 0s - loss: 9.2058e-05 - accuracy: 1.0000 ETA: 0s - loss: - 2s 653us/step - loss: 9.0673e-05 - accuracy: 1.0000\n",
      "Epoch 31/40\n",
      "2720/2720 [==============================] - 2s 651us/step - loss: 1.6329e-04 - accuracy: 1.00000s - loss: 1.6805e-04 - accuracy: \n",
      "Epoch 32/40\n",
      "2720/2720 [==============================] - 2s 654us/step - loss: 1.3207e-04 - accuracy: 1.00000s - loss: 1.0337e-04 - accuracy - ETA: 0s - loss: 9.3015e-05 - accuracy: 1.00\n",
      "Epoch 33/40\n",
      "2720/2720 [==============================] - 2s 653us/step - loss: 1.9831e-04 - accuracy: 1.00001s - loss: 1.2964e-0 - ETA: 0s - loss: 1.077\n",
      "Epoch 34/40\n",
      "2720/2720 [==============================] - 2s 655us/step - loss: 9.4939e-05 - accuracy: 1.00000s - loss: 9.6811e-05 - accuracy: 1.00 - ETA: 0s - loss: 9.6868e-05 - accuracy: 1.00\n",
      "Epoch 35/40\n",
      "2720/2720 [==============================] - 2s 657us/step - loss: 8.1339e-05 - accuracy: 1.00000s - loss: 9.2063e-05 - accuracy\n",
      "Epoch 36/40\n",
      "2720/2720 [==============================] - 2s 653us/step - loss: 9.6452e-05 - accuracy: 1.00000s - loss: 1.2145e-04 - accuracy: 1.00 - ETA: 0s - loss: 1.1678e-04 - accura - ETA: 0s - loss: 1.0185e-04 - accuracy: 1.\n",
      "Epoch 37/40\n",
      "2720/2720 [==============================] - 2s 657us/step - loss: 6.0751e-05 - accuracy: 1.0000\n",
      "Epoch 38/40\n",
      "2720/2720 [==============================] - 2s 653us/step - loss: 4.5854e-05 - accuracy: 1.00001s - loss: 1.6012e-05 - accuracy - ETA: 0s - loss: 1.4029e-05 - accuracy: 1. - ETA: 0s - loss: 1.5306e-0 - ETA: 0s - loss: 4.8962e-05 - accuracy: 1.\n",
      "Epoch 39/40\n",
      "2720/2720 [==============================] - 2s 654us/step - loss: 7.2804e-05 - accuracy: 1.00000s - loss: 9.4118e-05 - accuracy - ETA: 0s - loss: 8.8961e-05 - ac\n",
      "Epoch 40/40\n",
      "2720/2720 [==============================] - 2s 655us/step - loss: 1.4149e-04 - accuracy: 1.00001s -\n",
      "Epoch 1/40\n",
      "2720/2720 [==============================] - 2s 684us/step - loss: 0.3793 - accuracy: 0.8364\n",
      "Epoch 2/40\n",
      "2720/2720 [==============================] - 2s 645us/step - loss: 0.1798 - accuracy: 0.92651s - loss: 0.1834 - accuracy: 0.93 - ETA: 0s - loss: 0.1863 - accuracy: 0.92 - ETA: 0s - loss: 0.1825  - ETA: 0s - loss: 0.1885 - accu\n",
      "Epoch 3/40\n",
      "2720/2720 [==============================] - 2s 644us/step - loss: 0.1016 - accuracy: 0.96101s - loss: 0.1175 - accuracy: 0. - ETA: 1s - loss: 0.1147 - accura - ETA: 0s - loss: 0.1 - ETA: 0s - loss: 0.1072 - accuracy: \n",
      "Epoch 4/40\n",
      "2720/2720 [==============================] - 2s 648us/step - loss: 0.0694 - accuracy: 0.9743\n",
      "Epoch 5/40\n",
      "2720/2720 [==============================] - 2s 647us/step - loss: 0.0441 - accuracy: 0.98640s - loss: 0.0499 - accuracy: 0.98 - ETA: 0s - loss: 0.048 - ETA: 0s - loss: 0.0446 - accuracy\n",
      "Epoch 6/40\n",
      "2720/2720 [==============================] - 2s 647us/step - loss: 0.0352 - accuracy: 0.98821s - loss: 0.0175 - accuracy: 0. - ETA: 1s - loss: 0.0230 - accuracy - ETA: 1s - loss: 0.0206 - accuracy - ETA: 0s - loss: 0.0370 - accuracy:  - ETA: 0s - loss: 0.0381 - accuracy: 0.98 - ETA: 0s - loss: 0.0401 - accuracy: 0.98 - ETA: 0s - loss: 0.0416 - accuracy: 0.98 - ETA: 0s - loss: 0.0419 - accura - ETA: 0s - loss: 0.0380 - accuracy: \n",
      "Epoch 7/40\n",
      "2720/2720 [==============================] - 2s 648us/step - loss: 0.0302 - accuracy: 0.98971s - loss: 0.0105 - accuracy - ETA: \n",
      "Epoch 8/40\n",
      "2720/2720 [==============================] - 2s 647us/step - loss: 0.0251 - accuracy: 0.99191s - loss: 0.0175 - accuracy:  - ETA: 0s - loss: 0.0211 - accuracy: 0.99 - ETA: 0s - loss: 0.0201 - accuracy - ETA: 0s - loss: 0.0221 - accuracy: 0. - ETA: 0s - loss: 0.0219 - accuracy: 0. - ETA: 0s - loss: 0.0214 - accu\n",
      "Epoch 9/40\n",
      "2720/2720 [==============================] - 2s 649us/step - loss: 0.0251 - accuracy: 0.99190s - loss: 0.0142 - accuracy:  - ETA: 0s - loss: 0.0197  - ETA: 0s - loss: 0.0239 - accuracy\n",
      "Epoch 10/40\n",
      "2720/2720 [==============================] - 2s 642us/step - loss: 0.0211 - accuracy: 0.99261s - loss: 0.0124 -  - ETA: 0s - l\n",
      "Epoch 11/40\n",
      "2720/2720 [==============================] - 2s 644us/step - loss: 0.0170 - accuracy: 0.9937\n",
      "Epoch 12/40\n",
      "2720/2720 [==============================] - 2s 653us/step - loss: 0.0122 - accuracy: 0.9967\n",
      "Epoch 13/40\n",
      "2720/2720 [==============================] - 2s 652us/step - loss: 0.0107 - accuracy: 0.9967\n",
      "Epoch 14/40\n",
      "2720/2720 [==============================] - 2s 651us/step - loss: 0.0085 - accuracy: 0.99670s - loss: 0.0070 - accuracy: 0.99 - ETA: 0s - loss: 0.007\n",
      "Epoch 15/40\n",
      "2720/2720 [==============================] - 2s 652us/step - loss: 0.0126 - accuracy: 0.99601s - loss: 0.0 - ETA: 0s - loss: 0.0111 - accuracy: 0.99 - ETA: 0s - loss: 0.0107 \n",
      "Epoch 16/40\n",
      "2720/2720 [==============================] - 2s 650us/step - loss: 0.0050 - accuracy: 0.99781s - loss: 0.0068 - accuracy - ETA: 0s - loss: 0 - ETA: 0s - loss: 0.0046 - accuracy: \n",
      "Epoch 17/40\n",
      "2720/2720 [==============================] - 2s 652us/step - loss: 0.0049 - accuracy: 0.9982\n",
      "Epoch 18/40\n",
      "2720/2720 [==============================] - 2s 651us/step - loss: 0.0041 - accuracy: 0.99931s - loss: 0.0130 - accuracy: 0.99 - ETA: 1s - loss: 0.0126 - accuracy: 0.99 -\n",
      "Epoch 19/40\n",
      "2720/2720 [==============================] - 2s 654us/step - loss: 0.0049 - accuracy: 0.9982TA: 1s - loss: 9.6242e-04 - accuracy: 1.00 - ETA: 1s - loss: 0.0010 - accuracy: 1.0000   - ETA: 1s\n",
      "Epoch 20/40\n",
      "2720/2720 [==============================] - 2s 649us/step - loss: 0.0081 - accuracy: 0.99670s - loss: 0.0065 - accuracy:  - ETA: 0s - loss: 0.0077 - accura\n",
      "Epoch 21/40\n",
      "2720/2720 [==============================] - 2s 651us/step - loss: 0.0085 - accuracy: 0.99820s - loss: 0.0097 - accuracy: 0. - ETA: 0s - loss: 0.0091 - accuracy: 0.\n",
      "Epoch 22/40\n",
      "2720/2720 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9985 ETA: 1s - ETA: 0s - loss: 0.0026 - accuracy: 0.99 - ETA: 0s - loss: 0.0029 - accuracy: 0.99 - ETA: 0s - loss: 0.0034 - accuracy - 2s 654us/step - loss: 0.0037 - accuracy: 0.9982\n",
      "Epoch 23/40\n",
      "2720/2720 [==============================] - 2s 651us/step - loss: 0.0042 - accuracy: 0.99890s - loss: 0.0052  - ETA: 0s - loss: 0.0044 - accuracy: 0.99\n",
      "Epoch 24/40\n",
      "2720/2720 [==============================] - 2s 651us/step - loss: 0.0035 - accuracy: 0.99781s - loss: 0.0030 - accuracy: 0. - ETA: 0s - loss: 0.0036 - accuracy: 0. - ETA: 0s - loss: 0.0 - ETA: 0s - loss: 0.0037 - accuracy: 0.99 - ETA: 0s - loss: 0.0036 - accuracy: 0.99\n",
      "Epoch 25/40\n",
      "2720/2720 [==============================] - 2s 647us/step - loss: 3.8744e-04 - accuracy: 1.00000s - loss: 3.0441e-04 - accura - ETA: 0s - loss: 2.9627e-04 - \n",
      "Epoch 26/40\n",
      "2720/2720 [==============================] - 2s 669us/step - loss: 2.0273e-04 - accuracy: 1.00000s - loss: 1.4910e-04 \n",
      "Epoch 27/40\n",
      "2720/2720 [==============================] - 2s 650us/step - loss: 2.7927e-04 - accuracy: 1.00001s - loss: 1.8746e-04 - accuracy:  - ETA: 1s - l - ETA: 0s - loss: 2.4546e-04 - accura - ETA: 0s - loss: 2.3169e-04 - accuracy: 1.\n",
      "Epoch 28/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2720/2720 [==============================] - 2s 655us/step - loss: 0.0012 - accuracy: 0.9993: 1s - loss: 0.0022 - accuracy: 0.99 - ETA: 1s - loss: 0.0020 - accuracy: 0.99 - ETA: 0s - loss: 0.0019 - accura - ETA: 0s - loss: 0.0016 - accuracy: 0.99 - ETA: 0s - loss: 0.0015 -  - ETA: 0s - loss: 0.0012 - accuracy: 0.99\n",
      "Epoch 29/40\n",
      "2720/2720 [==============================] - 2s 647us/step - loss: 2.4646e-04 - accuracy: 1.00000s - loss: 2.9318e-04 - accuracy: 1.00 - ETA: 0s - loss: 2.7458e-04 - accu - ETA: 0s - loss: 2.4602e-04 - ac - ETA: 0s - loss: 2.5392e-04 - accuracy: 1.00\n",
      "Epoch 30/40\n",
      "2720/2720 [==============================] - 2s 647us/step - loss: 2.8961e-04 - accuracy: 1.00000s - loss: 3.5383e-04 - accuracy:  - ETA: 0s - loss: 3.6306e\n",
      "Epoch 31/40\n",
      "2720/2720 [==============================] - 2s 649us/step - loss: 1.5022e-04 - accuracy: 1.00001s - loss: 2.0973e-04 - accuracy: 1. - ETA: 1s - loss: 1.5355e-04 - ac - ETA: 0s - loss: 1.4983e-04 - accuracy:  - ETA: 0s - loss: 1.885\n",
      "Epoch 32/40\n",
      "2720/2720 [==============================] - 2s 651us/step - loss: 0.0050 - accuracy: 0.9978TA: 1s - loss: 9.2756e-05 - accuracy:  - ETA: 1s - loss: 4 - ETA: 0s - loss: 0.0041 - accura\n",
      "Epoch 33/40\n",
      "2720/2720 [==============================] - 2s 654us/step - loss: 9.0492e-04 - accuracy: 1.0000 - loss: 0.0011 - accuracy: 1. - ETA: 1s - loss: 0.0010 - accuracy: 1.00 - ETA: 1s - loss: 9.0142e-04 - accuracy: 1. - ETA: 1s - loss: 7.5233e-04 - accuracy: 1.00 - ETA: 1s - loss: 7.9263e-04 - accura - ETA: 0s - loss: 8.0541e-04 - accuracy: 1.00 - ETA: 0s - loss: 7.6310e\n",
      "Epoch 34/40\n",
      "2720/2720 [==============================] - 2s 655us/step - loss: 2.8282e-04 - accuracy: 1.00001s - loss: 4.3076e-04 - accu - ETA: 0s - loss: 4.2391e-04 - accura - ETA: 0s - loss: 3.5242e-04 - accuracy:  - ETA: 0s - loss: 3.1768e-04 - accura\n",
      "Epoch 35/40\n",
      "2720/2720 [==============================] - 2s 658us/step - loss: 1.9662e-04 - accuracy: 1.00001s - loss: 7.7565e-05 -  - ETA: 1s - loss: 1.9994e-04 - accuracy: 1. - ETA: 0s - loss: 1.8898e-04 - accuracy: 1. - ETA: 0s - loss: 1.6814e-04 - accuracy: 1. - ETA: 0s - loss: 1.5181e-0\n",
      "Epoch 36/40\n",
      "2720/2720 [==============================] - 2s 652us/step - loss: 2.6689e-04 - accuracy: 1.00000s - loss: 2.0243e-04 - accuracy: \n",
      "Epoch 37/40\n",
      "2720/2720 [==============================] - 2s 648us/step - loss: 9.8598e-04 - accuracy: 0.99960s - loss: 5.006\n",
      "Epoch 38/40\n",
      "2720/2720 [==============================] - 2s 643us/step - loss: 3.0916e-04 - accuracy: 1.00001s - loss: 5.6606e-04 - accuracy: 1.00 - ETA: 1s - loss: 4.9187e-04 - accuracy: 1.00 - ETA: 1s - loss: 4.3338e-04 - accuracy: 1. - ETA: 1s - loss: 3.6349e-0 - ETA: 0s - loss: 3.7504e-04 - ac - ETA: 0s - loss: 3.1904e-04 - accuracy: 1.00\n",
      "Epoch 39/40\n",
      "2720/2720 [==============================] - 2s 642us/step - loss: 1.5517e-04 - accuracy: 1.00000s - los\n",
      "Epoch 40/40\n",
      "2720/2720 [==============================] - 2s 637us/step - loss: 1.0358e-04 - accuracy: 1.00001s - loss: 8.5326e-05 -  - ETA: 0s - loss: 8.3011e-0\n",
      "Epoch 1/40\n",
      "2720/2720 [==============================] - 2s 682us/step - loss: 0.3526 - accuracy: 0.85371s - - ETA: 0s - loss: 0.3570 - accuracy: 0.85\n",
      "Epoch 2/40\n",
      "2720/2720 [==============================] - 2s 643us/step - loss: 0.2086 - accuracy: 0.91690s - loss: 0.2246 - accuracy - ETA: 0s - loss: 0.2274 - accuracy:  - ETA: 0s - loss: 0.2177 - \n",
      "Epoch 3/40\n",
      "2720/2720 [==============================] - 2s 646us/step - loss: 0.1137 - accuracy: 0.96071s - loss: 0.1314 - accuracy: 0.\n",
      "Epoch 4/40\n",
      "2720/2720 [==============================] - 2s 648us/step - loss: 0.0660 - accuracy: 0.97761s - loss: 0.0617 - accuracy: 0.97 - ETA: 1s - loss: 0.0610 - accu - ETA: 0s - loss: 0 - ETA: 0s - loss: 0.0653 - accuracy: 0.97 - ETA: 0s - loss: 0.0682 - accuracy: 0.\n",
      "Epoch 5/40\n",
      "2720/2720 [==============================] - 2s 649us/step - loss: 0.0476 - accuracy: 0.98530s - loss: 0.0452 - accuracy: 0.98 - ETA: 0s - loss: 0.0478 - accuracy:  - ETA: 0s - loss: 0.0476 - accuracy: 0. - ETA: 0s - loss: 0.0453 \n",
      "Epoch 6/40\n",
      "2720/2720 [==============================] - 2s 648us/step - loss: 0.0320 - accuracy: 0.98930s - loss: 0.0332 - accuracy: 0. - ETA: 0s - loss: 0.0316  - ETA: 0s - loss: 0.0328 - accuracy: \n",
      "Epoch 7/40\n",
      "2720/2720 [==============================] - 2s 650us/step - loss: 0.0291 - accuracy: 0.99081s - los - ETA: 0s - loss: 0.0305 - \n",
      "Epoch 8/40\n",
      "2720/2720 [==============================] - 2s 650us/step - loss: 0.0133 - accuracy: 0.99670s - loss: 0.0102 - accuracy: 0. - ETA: 0s - loss:\n",
      "Epoch 9/40\n",
      "2720/2720 [==============================] - 2s 652us/step - loss: 0.0221 - accuracy: 0.9934\n",
      "Epoch 10/40\n",
      "2720/2720 [==============================] - 2s 651us/step - loss: 0.0130 - accuracy: 0.99600s - loss: 0.0124 - accuracy: 0. - ETA: 0s - loss: 0.0123 - accuracy: 0.99 - ETA: 0s - loss: 0.0119 - accu\n",
      "Epoch 11/40\n",
      "2720/2720 [==============================] - 2s 654us/step - loss: 0.0161 - accuracy: 0.9952\n",
      "Epoch 12/40\n",
      "2720/2720 [==============================] - 2s 655us/step - loss: 0.0202 - accuracy: 0.99370s - loss: 0.0202 - accuracy: 0.99\n",
      "Epoch 13/40\n",
      "2720/2720 [==============================] - 2s 655us/step - loss: 0.0163 - accuracy: 0.99491s - loss: 0.0079 - accura - ETA: 1s - l - ETA: 0s - loss: 0.0161 - accuracy\n",
      "Epoch 14/40\n",
      "2720/2720 [==============================] - 2s 659us/step - loss: 0.0106 - accuracy: 0.99671s - loss: 0.0073 - accuracy: 0. - ETA: 1s - loss: 0.008 - ETA: 0s - loss: 0.0082 - ac\n",
      "Epoch 15/40\n",
      "2720/2720 [==============================] - 2s 657us/step - loss: 0.0069 - accuracy: 0.99741s - loss: 0.0075 - ac - ETA: 0s - loss: 0.0070 - accuracy: 0. - ETA: 0s - loss: 0.0063 - accuracy:  - ETA: 0s - loss: 0.0063 - ac\n",
      "Epoch 16/40\n",
      "2720/2720 [==============================] - 2s 655us/step - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 17/40\n",
      "2720/2720 [==============================] - 2s 654us/step - loss: 0.0172 - accuracy: 0.99411s - l - ETA: 0s - loss: 0.0200 - accura\n",
      "Epoch 18/40\n",
      "2720/2720 [==============================] - 2s 656us/step - loss: 0.0068 - accuracy: 0.99781s - loss: 0.0066 - accuracy:  - ETA: 1s - loss: 0.0076 - accuracy:  - ETA: 0s - loss:\n",
      "Epoch 19/40\n",
      "2720/2720 [==============================] - 2s 649us/step - loss: 0.0029 - accuracy: 0.99850s - loss: 0.0029  - ETA: 0s - loss: 0.0029 - accuracy: 0.99\n",
      "Epoch 20/40\n",
      "2720/2720 [==============================] - 2s 654us/step - loss: 0.0056 - accuracy: 0.99820s - l\n",
      "Epoch 21/40\n",
      "2720/2720 [==============================] - 2s 654us/step - loss: 0.0089 - accuracy: 0.99710s - loss: 0.0089 - accuracy: 0.99\n",
      "Epoch 22/40\n",
      "2720/2720 [==============================] - 2s 651us/step - loss: 0.0054 - accuracy: 0.99780s - loss: 0.0059 - accura - ETA: 0s - loss: 0.0050 - \n",
      "Epoch 23/40\n",
      "2720/2720 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9981 ETA:  - ETA: 0s - loss: 0.0042 - accuracy: 0. - 2s 655us/step - loss: 0.0040 - accuracy: 0.9982\n",
      "Epoch 24/40\n",
      "2720/2720 [==============================] - 2s 662us/step - loss: 8.3633e-04 - accuracy: 1.0000 loss: 0 - ETA: 0s - loss: 8.4793e-04 - accuracy\n",
      "Epoch 25/40\n",
      "2720/2720 [==============================] - 2s 664us/step - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 26/40\n",
      "2720/2720 [==============================] - 2s 670us/step - loss: 0.0017 - accuracy: 0.9989\n",
      "Epoch 27/40\n",
      "2720/2720 [==============================] - 2s 660us/step - loss: 6.7686e-04 - accuracy: 1.00000s - loss: 7.3692e-04 - accuracy: \n",
      "Epoch 28/40\n",
      "2720/2720 [==============================] - 2s 658us/step - loss: 3.7386e-04 - accuracy: 1.00001s - loss: 1.5898e-0 - ETA: 0s - loss: 1.6695e-04 - accuracy: 1.00 - ETA: 0s - loss: 1.5981e-04 - \n",
      "Epoch 29/40\n",
      "2720/2720 [==============================] - 2s 659us/step - loss: 0.0108 - accuracy: 0.99601s - loss: 0.0068 - accuracy:  - ETA: 1s\n",
      "Epoch 30/40\n",
      "2720/2720 [==============================] - 2s 690us/step - loss: 0.0365 - accuracy: 0.99010s - loss: 0.0393 - accuracy\n",
      "Epoch 31/40\n",
      "2720/2720 [==============================] - 2s 666us/step - loss: 0.0034 - accuracy: 0.9996\n",
      "Epoch 32/40\n",
      "2720/2720 [==============================] - 2s 660us/step - loss: 9.8375e-04 - accuracy: 1.0000 loss: 0.0 - ETA: 0s - loss: 0.0010 - accuracy: 1.00\n",
      "Epoch 33/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2720/2720 [==============================] - 2s 659us/step - loss: 6.3779e-04 - accuracy: 1.0000\n",
      "Epoch 34/40\n",
      "2720/2720 [==============================] - 2s 663us/step - loss: 6.1935e-04 - accuracy: 1.0000 loss: 0.0011 - accura - ETA: 1s - loss: 6.8785e-04 - accu - ETA: 0s - loss: 6.1653e-04 - accuracy - ETA: 0s - loss: 5.7706e-04 - ac\n",
      "Epoch 35/40\n",
      "2720/2720 [==============================] - 2s 665us/step - loss: 0.0018 - accuracy: 0.9993TA: 1s - - ETA: 0s - loss: 0.0018 - accuracy: 0.99 - ETA: 0s - loss: 0.0019 - accuracy: \n",
      "Epoch 36/40\n",
      "2720/2720 [==============================] - 2s 670us/step - loss: 9.9232e-04 - accuracy: 0.9996\n",
      "Epoch 37/40\n",
      "2720/2720 [==============================] - 2s 661us/step - loss: 4.1993e-04 - accuracy: 1.0000\n",
      "Epoch 38/40\n",
      "2720/2720 [==============================] - 2s 659us/step - loss: 2.8361e-04 - accuracy: 1.00001s - loss: 3.0737e-04 - accuracy: 1.00 - ETA: 1s - l\n",
      "Epoch 39/40\n",
      "2720/2720 [==============================] - 2s 665us/step - loss: 2.8103e-04 - accuracy: 1.00001s - loss: 5.9144e-04 -  - ETA: 0s - loss: 4.1144e-04 - accu - ETA: 0s - loss: 3.7323e-04 - accuracy: 1.00 - ETA: 0s - loss: 3.5944e-04 - accuracy:  - ETA: 0s - loss: 3.2208e-04 - accura\n",
      "Epoch 40/40\n",
      "2720/2720 [==============================] - 2s 657us/step - loss: 1.8546e-04 - accuracy: 1.00000s - loss: 1.9443e-04 - accu\n",
      "Epoch 1/40\n",
      "2720/2720 [==============================] - 2s 689us/step - loss: 0.3975 - accuracy: 0.81731s - loss: 0.5857  - ETA: 0s - los\n",
      "Epoch 2/40\n",
      "2720/2720 [==============================] - 2s 647us/step - loss: 0.1875 - accuracy: 0.92870s - loss: 0.1965 - accuracy: \n",
      "Epoch 3/40\n",
      "2720/2720 [==============================] - 2s 657us/step - loss: 0.0995 - accuracy: 0.96691s - loss: 0.1262 - accu - ETA: 1s -\n",
      "Epoch 4/40\n",
      "2720/2720 [==============================] - 2s 657us/step - loss: 0.0560 - accuracy: 0.97830s - loss: 0.0603 - accuracy:  - ETA: 0s - loss: 0.0577 - ac\n",
      "Epoch 5/40\n",
      "2720/2720 [==============================] - 2s 654us/step - loss: 0.0500 - accuracy: 0.98161s - los - ETA: 0s - loss: 0.0520 - accuracy: 0. - ETA: 0s - loss: 0.0523 - accuracy: 0.97 - ETA: 0s - loss: 0.0530 - accu\n",
      "Epoch 6/40\n",
      "2720/2720 [==============================] - 2s 653us/step - loss: 0.0417 - accuracy: 0.98710s - loss: 0.0444 - accuracy\n",
      "Epoch 7/40\n",
      "2720/2720 [==============================] - 2s 655us/step - loss: 0.0233 - accuracy: 0.99231s - loss: 0.024 - ETA: 0s - loss: 0.0241 - accuracy - ETA: 0s - loss: 0.0230 - accura\n",
      "Epoch 8/40\n",
      "2720/2720 [==============================] - 2s 653us/step - loss: 0.0270 - accuracy: 0.9904 ETA: 0s - loss: 0.0281 - accuracy: \n",
      "Epoch 9/40\n",
      "2720/2720 [==============================] - 2s 660us/step - loss: 0.0227 - accuracy: 0.99231s - loss: 0.0153 - accura - ETA: 1s - loss: 0.0148 - accuracy: 0.99 - ETA: 1s - loss: 0.013 - ETA: 0s - loss: 0.0187 - accuracy - ETA: 0s - loss: 0.0219 - accuracy: 0.\n",
      "Epoch 10/40\n",
      "2720/2720 [==============================] - 2s 653us/step - loss: 0.0155 - accuracy: 0.9941TA: 0s - loss: 0.0149 - accuracy: 0.\n",
      "Epoch 11/40\n",
      "2720/2720 [==============================] - 2s 660us/step - loss: 0.0234 - accuracy: 0.99341s - loss: 0.0126 - accuracy - ETA: 1s -\n",
      "Epoch 12/40\n",
      "2720/2720 [==============================] - 2s 655us/step - loss: 0.0261 - accuracy: 0.99151s - loss: - ETA: 0s - loss: 0.0294 - accu\n",
      "Epoch 13/40\n",
      "2720/2720 [==============================] - 2s 654us/step - loss: 0.0099 - accuracy: 0.99780s - loss: 0.0102 - \n",
      "Epoch 14/40\n",
      "2720/2720 [==============================] - 2s 652us/step - loss: 0.0062 - accuracy: 0.99930s - loss: 0.0083 -  - ETA: 0s - loss: 0.0068 - accuracy\n",
      "Epoch 15/40\n",
      "2720/2720 [==============================] - 2s 651us/step - loss: 0.0065 - accuracy: 0.99821s - loss: 0.0015 - accuracy: 1.00 - ETA: 1s - loss: 0.0017 - accuracy - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - ETA: 0s - loss:\n",
      "Epoch 16/40\n",
      "2720/2720 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9996 ETA: 0s - loss: 0.0038 - accu - ETA: 0s - loss: 0.0033 - accuracy - 2s 654us/step - loss: 0.0030 - accuracy: 0.9996\n",
      "Epoch 17/40\n",
      "2720/2720 [==============================] - 2s 654us/step - loss: 0.0023 - accuracy: 0.9996TA: 1s - loss: 0.0016 - ac - ETA: 0s - loss: 0.0017 - accuracy - ETA: 0s - loss: 0.0017 - accuracy:  - ETA: 0s - loss: 0.0023 - accuracy: \n",
      "Epoch 18/40\n",
      "2720/2720 [==============================] - 2s 654us/step - loss: 0.0043 - accuracy: 0.9989\n",
      "Epoch 19/40\n",
      "2720/2720 [==============================] - 2s 655us/step - loss: 0.0040 - accuracy: 0.99851s - loss: 0 - ETA: 0s - loss: 0.0031 - accuracy:  - ETA: 0s - loss: 0.0039 - accuracy: 0.99\n",
      "Epoch 20/40\n",
      "2720/2720 [==============================] - 2s 659us/step - loss: 0.0167 - accuracy: 0.99411s - loss: 0.0161 - accuracy:  - ETA: 1s\n",
      "Epoch 21/40\n",
      "2720/2720 [==============================] - 2s 652us/step - loss: 0.0125 - accuracy: 0.99631s - loss: 0.0188 - accuracy - ETA: 0s - loss: 0.0173 - accuracy - ETA: 0s - loss: 0.014\n",
      "Epoch 22/40\n",
      "2720/2720 [==============================] - 2s 654us/step - loss: 0.0038 - accuracy: 0.99890s - loss: 0.0036 - accura\n",
      "Epoch 23/40\n",
      "2720/2720 [==============================] - 2s 653us/step - loss: 0.0013 - accuracy: 1.0000: 1s - loss: 0.0016 - accuracy: 1. - ETA: 1s - l - ETA: 0s - loss: 0.0013 - accu\n",
      "Epoch 24/40\n",
      "2720/2720 [==============================] - 2s 658us/step - loss: 0.0049 - accuracy: 0.99891s - loss: 0.0057 - accuracy:  - ETA: 1s - loss: 0.0048 - accuracy - ETA: 0s - loss: 0.0046 - accuracy - ETA: 0s - loss: 0.0037 - accuracy - ETA: 0s - loss: 0.0044 - accu\n",
      "Epoch 25/40\n",
      "2720/2720 [==============================] - 2s 654us/step - loss: 0.0044 - accuracy: 0.99890s - loss: 0.0047 - accura\n",
      "Epoch 26/40\n",
      "2720/2720 [==============================] - 2s 659us/step - loss: 0.0058 - accuracy: 0.99781s - loss: 0.0 - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.0062 - accuracy: 0.\n",
      "Epoch 27/40\n",
      "2720/2720 [==============================] - 2s 656us/step - loss: 0.0165 - accuracy: 0.99561s - loss: 0.0214 -  - ETA: 0s - loss: 0.0167 - accuracy:  - ETA: 0s - loss: 0.0217 - accuracy - ETA: 0s - loss: 0.0184 - accura\n",
      "Epoch 28/40\n",
      "2720/2720 [==============================] - 2s 656us/step - loss: 0.0058 - accuracy: 0.99780s - loss: 0.0071 - accura - ETA: 0s - loss: 0.0070 - accura - ETA: 0s - loss: 0.0063 - accuracy\n",
      "Epoch 29/40\n",
      "2720/2720 [==============================] - 2s 658us/step - loss: 0.0011 - accuracy: 0.9996TA: 1s - loss: 7.1417e-04  - ETA: 0s - loss: 6.2380e-0\n",
      "Epoch 30/40\n",
      "2720/2720 [==============================] - 2s 660us/step - loss: 0.0027 - accuracy: 0.99961s - loss: 0.0037 - accuracy: 1. - ETA - ETA: 0s - loss: 0.0027 - accuracy: 0.\n",
      "Epoch 31/40\n",
      "2720/2720 [==============================] - 2s 670us/step - loss: 6.5012e-04 - accuracy: 1.00001s - loss: 0.0012 - ac - ETA: 0s - loss: 6.3054e-04 - accuracy: 1.00 - ETA: 0s - loss: 6.4\n",
      "Epoch 32/40\n",
      "2720/2720 [==============================] - 2s 663us/step - loss: 5.7104e-04 - accuracy: 1.0000 - loss: 9.2947e-04 - accura - ETA: 1s - loss: 5.3 - ETA: 0s - loss: 4.9946e-04 - accu\n",
      "Epoch 33/40\n",
      "2720/2720 [==============================] - 2s 670us/step - loss: 1.4438e-04 - accuracy: 1.00001s - loss: 1 - ETA: 0s - loss: 1.2015e-04 - accuracy: 1. - ETA: 0s - loss: 1.5909e-04 - \n",
      "Epoch 34/40\n",
      "2720/2720 [==============================] - 2s 668us/step - loss: 1.7949e-04 - accuracy: 1.00001s - loss: 8.4612e-05 - accuracy: 1. - ETA: 0s - loss: 7.8367e-05 - accura - ETA: 0s - loss: 1.4027e-04 - accura - ETA: 0s - loss: 1.3858e-04 - accuracy: 1. - ETA: 0s - loss: 1.3407e-04 - accuracy: 1.\n",
      "Epoch 35/40\n",
      "2720/2720 [==============================] - 2s 668us/step - loss: 2.4991e-04 - accuracy: 1.00001s - loss: 4.5344e - ETA: 0s - loss: 1.8463e-04 - accuracy: 1.00 - ETA: 0s - loss: 1.7521e-04 - accuracy:  - ETA: 0s - loss: 2.1272e-04 -  - ETA: 0s - loss: 2.2415e-04 - accuracy: 1.00\n",
      "Epoch 36/40\n",
      "2720/2720 [==============================] - 2s 669us/step - loss: 9.4192e-05 - accuracy: 1.00001s - loss: 1.0356e-04 - accuracy - ETA: 1s - los\n",
      "Epoch 37/40\n",
      "2720/2720 [==============================] - 2s 667us/step - loss: 1.0170e-04 - accuracy: 1.00001s - los\n",
      "Epoch 38/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2720/2720 [==============================] - 2s 661us/step - loss: 1.0168e-04 - accuracy: 1.00001s - loss: 4.1566e-0 - ETA: 0s - loss: 4.9847e-05 - accura\n",
      "Epoch 39/40\n",
      "2720/2720 [==============================] - 2s 652us/step - loss: 9.8299e-05 - accuracy: 1.00001s - loss: 8.3670e-05 -  - ETA: 0s - loss: 8.4028e-0\n",
      "Epoch 40/40\n",
      "2720/2720 [==============================] - 2s 662us/step - loss: 2.6808e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "for train_index,test_index in kf.split(X,y_train_mono):\n",
    "    X_tr,X_te=X[train_index,:],X[test_index,:]\n",
    "    y_tr,y_te=y[train_index],y[test_index]\n",
    "    y_tr_m,y_te_m=y_train_mono[train_index],y_train_mono[test_index]\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=(80, 80, 3), activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01, momentum=0.9, nesterov=True), \n",
    "              metrics=['accuracy'])\n",
    "    t0=time.time()\n",
    "    model.fit(X_tr, y_tr, batch_size=32, epochs=40, validation_split=None)\n",
    "    y_model = model.predict(X_te)\n",
    "    t1=time.time()\n",
    "    t=t1-t0\n",
    "    times.append(t)\n",
    "    y_model=np.argmax(y_model,axis=1)\n",
    "    acc_class,acc_overall=accuracy_score(y_te_m, y_model)\n",
    "    acc_scores.append(acc_overall)\n",
    "    conf_mat.append(conf(y_model,y_te_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from each fold =  [0.9926470588235294, 0.9897058823529412, 0.9941176470588236, 0.9882352941176471, 0.9941176470588236]\n",
      "Average Accuracy = 0.991764705882353\n",
      "Average Runtime = 71.82766485214233\n",
      "0.9937254901960785\n",
      "0.9858823529411765\n"
     ]
    }
   ],
   "source": [
    "avg_acc=np.sum(acc_scores)*1.0/k\n",
    "print('Accuracy from each fold =  {}'.format(acc_scores))\n",
    "print('Average Accuracy = {}'.format(avg_acc))\n",
    "print('Average Runtime = {}'.format(np.sum(np.array(times))*1.0/5))\n",
    "class0_acc=np.array([x[0][0]*1.0/(x[0][0]+x[0][1]) for x in conf_mat])\n",
    "class0_acc=np.sum(class0_acc)*1.0/5\n",
    "class1_acc=np.array([x[1][1]*1.0/(x[1][0]+x[1][1]) for x in conf_mat])\n",
    "class1_acc=np.sum(class1_acc)*1.0/5\n",
    "print(class0_acc)\n",
    "print(class1_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
